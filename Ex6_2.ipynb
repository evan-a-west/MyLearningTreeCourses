{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Exercise 6.2:\n",
    "# Working With a Neural Network Using Python\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "#### In this exercise, you will work with a neural network using Python. This exercise allows you to predict a target variable from a number of predictor variables. The goal is to show you how neural networks can be used to predict unknown values from a model trained on an existing data set.\n",
    "\n",
    "### Overview\n",
    "\n",
    "You will work on a data set called wines that you will import from a csv file. \n",
    "\n",
    "You will:<br>\n",
    "● Review the distribution of the target variable and transform it into a format suitable for use with a neural network<br>\n",
    "● Examine the predictor variables<br>\n",
    "● Train a neural network that can be used to make future predictions<br><br>\n",
    "\n",
    "**Pre-step: Execute the following cell in order to suppress warning messages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Major Step 1: Data loading and text preprocessing**\n",
    "\n",
    "1. ❏ Import the **pandas** package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. ❏ Import the **wines.csv** dataset into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"wines.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. ❏ View the columns in the dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'Alcohol', 'Malic_acid', 'Ash', 'Alcalinity_of_ash',\n",
       "       'Magnesium', 'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols',\n",
       "       'Proanthocyanins', 'Color_intensity', 'Hue',\n",
       "       'OD280_OD315_of_diluted_wines', 'Proline'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. ❏ View a preview of the wines dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280_OD315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label  Alcohol  Malic_acid   Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0      1    14.23        1.71  2.43               15.6        127   \n",
       "1      1    13.20        1.78  2.14               11.2        100   \n",
       "2      1    13.16        2.36  2.67               18.6        101   \n",
       "3      1    14.37        1.95  2.50               16.8        113   \n",
       "4      1    13.24        2.59  2.87               21.0        118   \n",
       "\n",
       "   Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0           2.80        3.06                  0.28             2.29   \n",
       "1           2.65        2.76                  0.26             1.28   \n",
       "2           2.80        3.24                  0.30             2.81   \n",
       "3           3.85        3.49                  0.24             2.18   \n",
       "4           2.80        2.69                  0.39             1.82   \n",
       "\n",
       "   Color_intensity   Hue  OD280_OD315_of_diluted_wines  Proline  \n",
       "0             5.64  1.04                          3.92     1065  \n",
       "1             4.38  1.05                          3.40     1050  \n",
       "2             5.68  1.03                          3.17     1185  \n",
       "3             7.80  0.86                          3.45     1480  \n",
       "4             4.32  1.04                          2.93      735  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 3], dtype=int64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(data.shape)\n",
    "data.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280_OD315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Alcohol  Malic_acid   Ash  Alcalinity_of_ash  Magnesium  Total_phenols  \\\n",
       "0      14.23        1.71  2.43               15.6        127           2.80   \n",
       "1      13.20        1.78  2.14               11.2        100           2.65   \n",
       "2      13.16        2.36  2.67               18.6        101           2.80   \n",
       "3      14.37        1.95  2.50               16.8        113           3.85   \n",
       "4      13.24        2.59  2.87               21.0        118           2.80   \n",
       "..       ...         ...   ...                ...        ...            ...   \n",
       "173    13.71        5.65  2.45               20.5         95           1.68   \n",
       "174    13.40        3.91  2.48               23.0        102           1.80   \n",
       "175    13.27        4.28  2.26               20.0        120           1.59   \n",
       "176    13.17        2.59  2.37               20.0        120           1.65   \n",
       "177    14.13        4.10  2.74               24.5         96           2.05   \n",
       "\n",
       "     Flavanoids  Nonflavanoid_phenols  Proanthocyanins  Color_intensity   Hue  \\\n",
       "0          3.06                  0.28             2.29             5.64  1.04   \n",
       "1          2.76                  0.26             1.28             4.38  1.05   \n",
       "2          3.24                  0.30             2.81             5.68  1.03   \n",
       "3          3.49                  0.24             2.18             7.80  0.86   \n",
       "4          2.69                  0.39             1.82             4.32  1.04   \n",
       "..          ...                   ...              ...              ...   ...   \n",
       "173        0.61                  0.52             1.06             7.70  0.64   \n",
       "174        0.75                  0.43             1.41             7.30  0.70   \n",
       "175        0.69                  0.43             1.35            10.20  0.59   \n",
       "176        0.68                  0.53             1.46             9.30  0.60   \n",
       "177        0.76                  0.56             1.35             9.20  0.61   \n",
       "\n",
       "     OD280_OD315_of_diluted_wines  Proline  \n",
       "0                            3.92     1065  \n",
       "1                            3.40     1050  \n",
       "2                            3.17     1185  \n",
       "3                            3.45     1480  \n",
       "4                            2.93      735  \n",
       "..                            ...      ...  \n",
       "173                          1.74      740  \n",
       "174                          1.56      750  \n",
       "175                          1.56      835  \n",
       "176                          1.62      840  \n",
       "177                          1.60      560  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[:, 1:data.shape[1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. ❏ Normalize the data in the dataframe through scaling using the **MinMaxScaler** library from **sklearn.preprocessing**<br><br>\n",
    "*Info: MinMaxScaler rescales the data set such that all feature values are in the range 0 to 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "# dataScaled = pd.DataFrame(preprocessing.minmax_scale(data), columns=data.columns)\n",
    "dataScaled = pd.DataFrame(scaler.fit_transform(data.iloc[:, 1:data.shape[1]]), columns=data.iloc[:, 1:data.shape[1]].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. ❏ View the scaled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alcohol</th>\n",
       "      <th>Malic_acid</th>\n",
       "      <th>Ash</th>\n",
       "      <th>Alcalinity_of_ash</th>\n",
       "      <th>Magnesium</th>\n",
       "      <th>Total_phenols</th>\n",
       "      <th>Flavanoids</th>\n",
       "      <th>Nonflavanoid_phenols</th>\n",
       "      <th>Proanthocyanins</th>\n",
       "      <th>Color_intensity</th>\n",
       "      <th>Hue</th>\n",
       "      <th>OD280_OD315_of_diluted_wines</th>\n",
       "      <th>Proline</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.842105</td>\n",
       "      <td>0.191700</td>\n",
       "      <td>0.572193</td>\n",
       "      <td>0.257732</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.573840</td>\n",
       "      <td>0.283019</td>\n",
       "      <td>0.593060</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.970696</td>\n",
       "      <td>0.561341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.571053</td>\n",
       "      <td>0.205534</td>\n",
       "      <td>0.417112</td>\n",
       "      <td>0.030928</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.575862</td>\n",
       "      <td>0.510549</td>\n",
       "      <td>0.245283</td>\n",
       "      <td>0.274448</td>\n",
       "      <td>0.264505</td>\n",
       "      <td>0.463415</td>\n",
       "      <td>0.780220</td>\n",
       "      <td>0.550642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.560526</td>\n",
       "      <td>0.320158</td>\n",
       "      <td>0.700535</td>\n",
       "      <td>0.412371</td>\n",
       "      <td>0.336957</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.611814</td>\n",
       "      <td>0.320755</td>\n",
       "      <td>0.757098</td>\n",
       "      <td>0.375427</td>\n",
       "      <td>0.447154</td>\n",
       "      <td>0.695971</td>\n",
       "      <td>0.646933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.878947</td>\n",
       "      <td>0.239130</td>\n",
       "      <td>0.609626</td>\n",
       "      <td>0.319588</td>\n",
       "      <td>0.467391</td>\n",
       "      <td>0.989655</td>\n",
       "      <td>0.664557</td>\n",
       "      <td>0.207547</td>\n",
       "      <td>0.558360</td>\n",
       "      <td>0.556314</td>\n",
       "      <td>0.308943</td>\n",
       "      <td>0.798535</td>\n",
       "      <td>0.857347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.581579</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.807487</td>\n",
       "      <td>0.536082</td>\n",
       "      <td>0.521739</td>\n",
       "      <td>0.627586</td>\n",
       "      <td>0.495781</td>\n",
       "      <td>0.490566</td>\n",
       "      <td>0.444795</td>\n",
       "      <td>0.259386</td>\n",
       "      <td>0.455285</td>\n",
       "      <td>0.608059</td>\n",
       "      <td>0.325963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0.705263</td>\n",
       "      <td>0.970356</td>\n",
       "      <td>0.582888</td>\n",
       "      <td>0.510309</td>\n",
       "      <td>0.271739</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.056962</td>\n",
       "      <td>0.735849</td>\n",
       "      <td>0.205047</td>\n",
       "      <td>0.547782</td>\n",
       "      <td>0.130081</td>\n",
       "      <td>0.172161</td>\n",
       "      <td>0.329529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0.623684</td>\n",
       "      <td>0.626482</td>\n",
       "      <td>0.598930</td>\n",
       "      <td>0.639175</td>\n",
       "      <td>0.347826</td>\n",
       "      <td>0.282759</td>\n",
       "      <td>0.086498</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.315457</td>\n",
       "      <td>0.513652</td>\n",
       "      <td>0.178862</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.336662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0.589474</td>\n",
       "      <td>0.699605</td>\n",
       "      <td>0.481283</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.210345</td>\n",
       "      <td>0.073840</td>\n",
       "      <td>0.566038</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.761092</td>\n",
       "      <td>0.089431</td>\n",
       "      <td>0.106227</td>\n",
       "      <td>0.397290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0.563158</td>\n",
       "      <td>0.365613</td>\n",
       "      <td>0.540107</td>\n",
       "      <td>0.484536</td>\n",
       "      <td>0.543478</td>\n",
       "      <td>0.231034</td>\n",
       "      <td>0.071730</td>\n",
       "      <td>0.754717</td>\n",
       "      <td>0.331230</td>\n",
       "      <td>0.684300</td>\n",
       "      <td>0.097561</td>\n",
       "      <td>0.128205</td>\n",
       "      <td>0.400856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0.815789</td>\n",
       "      <td>0.664032</td>\n",
       "      <td>0.737968</td>\n",
       "      <td>0.716495</td>\n",
       "      <td>0.282609</td>\n",
       "      <td>0.368966</td>\n",
       "      <td>0.088608</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.296530</td>\n",
       "      <td>0.675768</td>\n",
       "      <td>0.105691</td>\n",
       "      <td>0.120879</td>\n",
       "      <td>0.201141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Alcohol  Malic_acid       Ash  Alcalinity_of_ash  Magnesium  \\\n",
       "0    0.842105    0.191700  0.572193           0.257732   0.619565   \n",
       "1    0.571053    0.205534  0.417112           0.030928   0.326087   \n",
       "2    0.560526    0.320158  0.700535           0.412371   0.336957   \n",
       "3    0.878947    0.239130  0.609626           0.319588   0.467391   \n",
       "4    0.581579    0.365613  0.807487           0.536082   0.521739   \n",
       "..        ...         ...       ...                ...        ...   \n",
       "173  0.705263    0.970356  0.582888           0.510309   0.271739   \n",
       "174  0.623684    0.626482  0.598930           0.639175   0.347826   \n",
       "175  0.589474    0.699605  0.481283           0.484536   0.543478   \n",
       "176  0.563158    0.365613  0.540107           0.484536   0.543478   \n",
       "177  0.815789    0.664032  0.737968           0.716495   0.282609   \n",
       "\n",
       "     Total_phenols  Flavanoids  Nonflavanoid_phenols  Proanthocyanins  \\\n",
       "0         0.627586    0.573840              0.283019         0.593060   \n",
       "1         0.575862    0.510549              0.245283         0.274448   \n",
       "2         0.627586    0.611814              0.320755         0.757098   \n",
       "3         0.989655    0.664557              0.207547         0.558360   \n",
       "4         0.627586    0.495781              0.490566         0.444795   \n",
       "..             ...         ...                   ...              ...   \n",
       "173       0.241379    0.056962              0.735849         0.205047   \n",
       "174       0.282759    0.086498              0.566038         0.315457   \n",
       "175       0.210345    0.073840              0.566038         0.296530   \n",
       "176       0.231034    0.071730              0.754717         0.331230   \n",
       "177       0.368966    0.088608              0.811321         0.296530   \n",
       "\n",
       "     Color_intensity       Hue  OD280_OD315_of_diluted_wines   Proline  \n",
       "0           0.372014  0.455285                      0.970696  0.561341  \n",
       "1           0.264505  0.463415                      0.780220  0.550642  \n",
       "2           0.375427  0.447154                      0.695971  0.646933  \n",
       "3           0.556314  0.308943                      0.798535  0.857347  \n",
       "4           0.259386  0.455285                      0.608059  0.325963  \n",
       "..               ...       ...                           ...       ...  \n",
       "173         0.547782  0.130081                      0.172161  0.329529  \n",
       "174         0.513652  0.178862                      0.106227  0.336662  \n",
       "175         0.761092  0.089431                      0.106227  0.397290  \n",
       "176         0.684300  0.097561                      0.128205  0.400856  \n",
       "177         0.675768  0.105691                      0.120879  0.201141  \n",
       "\n",
       "[178 rows x 13 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataScaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. ❏ One hot encode the target variable into three separate variables. Use the prefix **label** for each of the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label_1</th>\n",
       "      <th>label_2</th>\n",
       "      <th>label_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label_1  label_2  label_3\n",
       "0          1        0        0\n",
       "1          1        0        0\n",
       "2          1        0        0\n",
       "3          1        0        0\n",
       "4          1        0        0\n",
       "..       ...      ...      ...\n",
       "173        0        0        1\n",
       "174        0        0        1\n",
       "175        0        0        1\n",
       "176        0        0        1\n",
       "177        0        0        1\n",
       "\n",
       "[178 rows x 3 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oneHotEncoding = pd.get_dummies(data.label, prefix=\"label\", prefix_sep=\"_\", drop_first=False)\n",
    "oneHotEncoding\n",
    "\n",
    "# dataScaled = dataScaled.drop(columns=[\"label\"]).join(dummies)\n",
    "# dataScaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. ❏ Split the dataset into a training and test dataset using the **train_test_split()** function from **sklearn.model_selection**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataScaled, oneHotEncoding, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. ❏ Examing the size of the resulting 4 datasets using the **.shape** attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 13)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 13)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(133, 3)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(45, 3)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. ❏ Instantiate a neural net model. Experiment with hidden layer sizes. (eg.10,10,10). Use a **tanh** activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': 'tanh',\n",
       " 'alpha': 0.0001,\n",
       " 'batch_size': 'auto',\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.999,\n",
       " 'early_stopping': False,\n",
       " 'epsilon': 1e-08,\n",
       " 'hidden_layer_sizes': (10, 10, 10),\n",
       " 'learning_rate': 'constant',\n",
       " 'learning_rate_init': 0.001,\n",
       " 'max_fun': 15000,\n",
       " 'max_iter': 200,\n",
       " 'momentum': 0.9,\n",
       " 'n_iter_no_change': 10,\n",
       " 'nesterovs_momentum': True,\n",
       " 'power_t': 0.5,\n",
       " 'random_state': 42,\n",
       " 'shuffle': True,\n",
       " 'solver': 'adam',\n",
       " 'tol': 0.0001,\n",
       " 'validation_fraction': 0.1,\n",
       " 'verbose': False,\n",
       " 'warm_start': False}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(10, 10, 10), random_state=42, activation='tanh')\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11. ❏ Train the model with the training datasets (the prediction dataset and the target dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', hidden_layer_sizes=(10, 10, 10),\n",
       "              random_state=42)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. ❏ Using the trained model, generate predictions for the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 0, 1, 0, 1, 2, 1, 2, 0, 2, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "       1, 2, 2, 2, 1, 1, 1, 0, 0, 1, 2, 0, 0, 0, 2, 2, 1, 2, 0, 1, 1, 1,\n",
       "       2], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y_test.values.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. ❏ Build a **confusion matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 3, 15,  0],\n",
       "       [ 0,  1, 11]], dtype=int64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "y_test.values.argmax()\n",
    "confusion_matrix(y_test.values.argmax(axis=1), y_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "14. ❏ Build a **classification report** for the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.93      0.93        15\n",
      "           1       0.94      0.83      0.88        18\n",
      "           2       1.00      1.00      1.00        12\n",
      "\n",
      "   micro avg       0.95      0.91      0.93        45\n",
      "   macro avg       0.96      0.92      0.94        45\n",
      "weighted avg       0.95      0.91      0.93        45\n",
      " samples avg       0.90      0.91      0.90        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataScaled.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataScaled.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sea\n",
    "sea.pairplot(dataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataScaled.columns.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(n_components=13)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=dataScaled.columns.shape[0])\n",
    "pca.fit(dataScaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.2200922 , 0.10246084, 0.04624247, 0.04011226, 0.03005877,\n",
       "       0.02516286, 0.01978926, 0.01301012, 0.01228411, 0.01215769,\n",
       "       0.0074605 , 0.00687688, 0.00440241])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.40749485, 0.18970352, 0.08561671, 0.07426678, 0.05565301,\n",
       "       0.04658837, 0.03663929, 0.02408789, 0.02274371, 0.02250965,\n",
       "       0.01381292, 0.01273236, 0.00815095])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Alcohol', 'Malic_acid', 'Ash', 'Alcalinity_of_ash', 'Magnesium',\n",
      "       'Total_phenols', 'Flavanoids', 'Nonflavanoid_phenols',\n",
      "       'Proanthocyanins', 'Color_intensity', 'Hue',\n",
      "       'OD280_OD315_of_diluted_wines', 'Proline'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(dataScaled.columns, pca.explained_variance_ratio_)\n",
    "print(dataScaled.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Saving the model\n",
    "import pickle\n",
    "pickle.dump(clf, open(\"clf20220324.pkl\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bytes"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can serialize the object in a binary string\n",
    "saved_clf = pickle.dumps(clf)\n",
    "type(saved_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.neural_network._multilayer_perceptron.MLPClassifier"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Read the data. Be careful where you read the file from, because executable code can be stored in pickle data\n",
    "fredie = pickle.load(open(\"clf20220324.pkl\", 'rb'))\n",
    "type(fredie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(0, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'hidden_layer_sizes': [(10,10,10), (10,10), (10), (8,8,8), (12,12,12)],\n",
    "    'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
    "    'solver': ['lbfgs', 'sgd', 'adam'],\n",
    "    'random_state' : np.arange(0, 42)\n",
    "    }\n",
    "\n",
    "clf_grid = GridSearchCV(\n",
    "    estimator=MLPClassifier(),\n",
    "    param_grid=params,\n",
    "    cv=5,\n",
    "    n_jobs=5,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2520 candidates, totalling 12600 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=MLPClassifier(), n_jobs=5,\n",
       "             param_grid={'activation': ['identity', 'logistic', 'tanh', 'relu'],\n",
       "                         'hidden_layer_sizes': [(10, 10, 10), (10, 10), 10,\n",
       "                                                (8, 8, 8), (12, 12, 12)],\n",
       "                         'random_state': array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41]),\n",
       "                         'solver': ['lbfgs', 'sgd', 'adam']},\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='logistic', hidden_layer_sizes=(8, 8, 8),\n",
       "              random_state=28, solver='lbfgs')"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_best = clf_grid.best_estimator_\n",
    "clf_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[15,  0,  0],\n",
       "       [ 0, 18,  0],\n",
       "       [ 0,  0, 12]], dtype=int64)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_best = clf_best.predict(X_test)\n",
    "y_pred_best\n",
    "\n",
    "confusion_matrix(y_test.values.argmax(axis=1), y_pred_best.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Congratulations! You have completed the exercise.**</center>"
   ]
  },
  {
   "attachments": {
    "image.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image.png](attachment:image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>**This is the end of the exercise.**</center>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
